{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports required by all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing.shared_memory import SharedMemory\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# my imports\n",
    "from exp_utils import single_exp, load_cms, load_prior, set_cms_eps, unload_cms, attack_real_users, \\\n",
    "    attack, run_utility_vs_eps\n",
    "from cms import CMS\n",
    "from plot_lib import init_plotting, init_figure, plot_prec_nr, plot_conf, plot_gammadelta, \\\n",
    "    parse_pickle_prec_nr, plot_gammadelta_heatmap, plot_spl_conf, colors_to_use\n",
    "from exp_params import ExpParams\n",
    "from base_distribution import zip_pdf, random_pdf\n",
    "\n",
    "# initialize plotting format\n",
    "init_plotting('ieee')\n",
    "\n",
    "# prepare relevant folders\n",
    "exps_folder = 'pickles/experiments/'\n",
    "hash_tables_folder = 'pickles/hash_tables/'\n",
    "hadamard_matrices_folder = 'pickles/hadamard_matrices/'\n",
    "priors_folder = 'pickles/priors/'\n",
    "imgs_folder = 'imgs/'\n",
    "p_omegas_folder = 'pickles/p_omegas/'\n",
    "\n",
    "os.makedirs(exps_folder, exist_ok=True)\n",
    "os.makedirs(hash_tables_folder, exist_ok=True)\n",
    "os.makedirs(hadamard_matrices_folder, exist_ok=True)\n",
    "os.makedirs(priors_folder, exist_ok=True)\n",
    "os.makedirs(imgs_folder, exist_ok=True)\n",
    "os.makedirs(p_omegas_folder, exist_ok=True)\n",
    "\n",
    "# initialize logging to track experiment status after exiting notebook\n",
    "logging.basicConfig(filename='pickles/log.txt', filemode='a',\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    datefmt='%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "# number of users to use in main experiments (default: 150000)\n",
    "num_users = 150000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack on Emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis parameters\n",
    "setting = 'emojis'\n",
    "U, m, k, eps = 2600, 1024, 65536, 4\n",
    "pool_sizes = [228, 228, 228, 228, 228, 228]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "kappa = 1.2\n",
    "ns = [7, 30, 90, 180]\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{setting} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{setting} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    # generate/load zipf p_\\Omega\n",
    "    if not os.path.isfile(p_omega):\n",
    "        universe = np.arange(U)\n",
    "        p_omega_f = np.concatenate([zip_pdf(kappa, p) for p in pool_sizes] +\n",
    "                                [zip_pdf(kappa, U - sum(pool_sizes))])\n",
    "        p_omega_f /= p_omega_f.sum()\n",
    "        pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "    logging.info(f'{setting} => loaded p_omega')\n",
    "\n",
    "    # generate/load prior\n",
    "    load_prior(U, m, k, eps, pool_sizes, p_omega, prior)\n",
    "    logging.info(f'{setting} => loaded prior ({prior})')\n",
    "    logging.info(f'{setting} => finished setting up')\n",
    "\n",
    "    for prior_type in ['estimated', 'uniform']:\n",
    "        curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "        # pack experiment parameters into object\n",
    "        sub_folder = f'{setting}_{prior_type}_prior'\n",
    "        exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "        exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "            exp_db_filename=exp_db_filename, reps=num_users,\n",
    "            p_omega=p_omega, prior=curr_prior)\n",
    "        \n",
    "        logging.info(f'{setting}, {prior_type} => starting')\n",
    "\n",
    "        for n in ns:\n",
    "            exp_params.n = n\n",
    "            logging.info(f'{setting}, {prior_type}, {n} => starting')\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'n = {n}: ')\n",
    "            single_exp(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{setting}, {prior_type}, {n} => finished')\n",
    "\n",
    "            pickle.dump(exp_params.EXP_DB, open(exp_db_filename, 'wb'))\n",
    "\n",
    "        logging.info(f'{setting}, {prior_type} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "## run non private\n",
    "np_cms = (U, U, math.inf, 0, None, None)\n",
    "sub_folder = f'{setting}_non_private'\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "exp_params = ExpParams(np_cms, pool_sizes,\n",
    "    exp_db_filename=exp_db_filename, reps=num_users, p_omega=p_omega)\n",
    "for n in ns:\n",
    "    exp_params.n = n\n",
    "    logging.info(f'{setting}, non-private, {n} => starting')\n",
    "    pbar = tqdm(total=exp_params.reps, desc=f'n = {n}: ')\n",
    "    single_exp(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "    logging.info(f'{setting}, non-private, {n} => finished')\n",
    "\n",
    "    pickle.dump(exp_params.EXP_DB, open(exp_db_filename, 'wb'))\n",
    "logging.info(f'{setting} => finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision vs null rate\n",
    "fig, axs = init_figure(1, 2, 'ieee_double')\n",
    "setting = 'emojis'\n",
    "n_pools = 6\n",
    "\n",
    "# plot uniform prior\n",
    "AUC_DB = plot_prec_nr(f'{setting}_uniform_prior', axs[0], n_pools=n_pools)\n",
    "# plot non-private\n",
    "AUC_DB = plot_prec_nr(f'{setting}_non_private', axs[0], n_pools=n_pools,\n",
    "    AUC_DB=AUC_DB, nonprivate=True)\n",
    "axs[0].set_title('$\\\\text{Adv}_\\\\textit{weak}$')\n",
    "\n",
    "# plot estimated prior\n",
    "AUC_DB = plot_prec_nr(f'{setting}_estimated_prior', axs[1], n_pools=n_pools,\n",
    "    AUC_DB=AUC_DB)\n",
    "# plot non-private\n",
    "plot_prec_nr(f'{setting}_non_private', axs[1], n_pools=n_pools, nonprivate=True)\n",
    "axs[1].set_title('$\\\\text{Adv}_\\\\textit{strong}$')\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "# custom legend\n",
    "h, l = axs[-1].get_legend_handles_labels()\n",
    "handles = h[1:5] + h[:1] + h[6:]\n",
    "labels = l[1:5] + l[:1] + l[6:]\n",
    "axs[-1].legend(handles, labels, bbox_to_anchor=(1.1, 1.0375), ncol=2,\n",
    "    columnspacing=0.5, title='\\\\hphantom{\\\\text{.}} \\\\hspace{0.2cm} '\n",
    "    '\\\\textbf{CMS} \\\\hspace{0.8cm} \\\\textbf{Non-Private}')\n",
    "\n",
    "fig.tight_layout(w_pad=0)\n",
    "AUC_DB.to_pickle(f'imgs/{setting}.pkl')\n",
    "fig.savefig(f'imgs/{setting}_prec_mr.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf score\n",
    "setting = 'emojis'\n",
    "\n",
    "fig, axs = init_figure(1, 2, 'ieee')\n",
    "plot_conf(f'{setting}_uniform_prior', axs[0])\n",
    "axs[0].set_title('$\\\\text{Adv}_\\\\textit{weak}$')\n",
    "\n",
    "plot_conf(f'{setting}_estimated_prior', axs[1])\n",
    "axs[1].set_title('$\\\\text{Adv}_\\\\textit{strong}$')\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "# legend\n",
    "axs[-1].legend(bbox_to_anchor=(1.1, 1.0375))\n",
    "\n",
    "fig.savefig(f'imgs/{setting}_conf.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour (uniform)\n",
    "setting = 'emojis'\n",
    "prior_type = 'uniform'\n",
    "exp_name = f'{setting}_{prior_type}_prior'\n",
    "n_pools = 6\n",
    "\n",
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "plot_gammadelta(exp_name, axs, n_pools)\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig(f'imgs/{exp_name}_cont.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour (estimated)\n",
    "setting = 'emojis'\n",
    "prior_type = 'estimated'\n",
    "exp_name = f'{setting}_{prior_type}_prior'\n",
    "n_pools = 6\n",
    "\n",
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "plot_gammadelta(exp_name, axs, n_pools)\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig(f'imgs/{exp_name}_cont.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack on News/Web Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web domains parameters\n",
    "setting = 'news'\n",
    "U, m, k, eps = 2000, 1024, 65536, 8\n",
    "pool_sizes = [14, 13, 13, 10, 10]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{setting} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{setting} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    # generate/load random p_\\Omega\n",
    "    if not os.path.isfile(p_omega):\n",
    "        universe = np.arange(U)\n",
    "        p_omega_f = np.concatenate([random_pdf(p) for p in pool_sizes] +\n",
    "                                   [random_pdf(U - sum(pool_sizes))])\n",
    "        p_omega_f /= p_omega_f.sum()\n",
    "\n",
    "        pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "    logging.info(f'{setting} => loaded p_omega')\n",
    "\n",
    "    # generate/load prior\n",
    "    load_prior(U, m, k, eps, pool_sizes, p_omega, prior)\n",
    "    logging.info(f'{setting} => loaded prior')\n",
    "    logging.info(f'{setting} => finished setting up')\n",
    "\n",
    "    for prior_type in ['estimated', 'uniform']:\n",
    "        curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "        # pack experiment parameters into object\n",
    "        sub_folder = f'{setting}_{prior_type}_prior'\n",
    "        exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "        exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "            exp_db_filename=exp_db_filename, reps=num_users,\n",
    "            p_omega=p_omega, prior=curr_prior)\n",
    "        \n",
    "        logging.info(f'{setting}, {prior_type} => starting')\n",
    "\n",
    "        for n in ns:\n",
    "            exp_params.n = n\n",
    "            logging.info(f'{setting}, {prior_type}, {n} => starting')\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'n = {n}: ')\n",
    "            single_exp(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{setting}, {prior_type}, {n} => finished')\n",
    "\n",
    "            pickle.dump(exp_params.EXP_DB, open(exp_db_filename, 'wb'))\n",
    "\n",
    "        logging.info(f'{setting}, {prior_type} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "## run non private\n",
    "np_cms = (U, U, math.inf, 0, None, None)\n",
    "sub_folder = f'{setting}_non_private'\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "exp_params = ExpParams(np_cms, pool_sizes,\n",
    "    exp_db_filename=exp_db_filename, reps=num_users, p_omega=p_omega)\n",
    "for n in ns:\n",
    "    exp_params.n = n\n",
    "    logging.info(f'{setting}, non-private, {n} => starting')\n",
    "    pbar = tqdm(total=exp_params.reps, desc=f'n = {n}: ')\n",
    "    single_exp(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "    logging.info(f'{setting}, non-private, {n} => finished')\n",
    "\n",
    "    pickle.dump(exp_params.EXP_DB, open(exp_db_filename, 'wb'))\n",
    "logging.info(f'{setting} => finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision vs null rate\n",
    "fig, axs = init_figure(1, 2, 'ieee_double')\n",
    "setting = 'news'\n",
    "n_pools = 5\n",
    "\n",
    "# plot uniform prior\n",
    "AUC_DB = plot_prec_nr(f'{setting}_uniform_prior', axs[0], n_pools=n_pools)\n",
    "# plot non-private\n",
    "AUC_DB = plot_prec_nr(f'{setting}_non_private', axs[0], n_pools=n_pools,\n",
    "    AUC_DB=AUC_DB, nonprivate=True)\n",
    "# plot estimated prior\n",
    "AUC_DB = plot_prec_nr(f'{setting}_estimated_prior', axs[1], n_pools=n_pools,\n",
    "    AUC_DB=AUC_DB)\n",
    "# plot non-private\n",
    "plot_prec_nr(f'{setting}_non_private', axs[1], n_pools=n_pools, nonprivate=True)\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "# custom legend\n",
    "h, l = axs[-1].get_legend_handles_labels()\n",
    "handles = h[1:5] + h[:1] + h[6:]\n",
    "labels = l[1:5] + l[:1] + l[6:]\n",
    "axs[-1].legend(handles, labels, bbox_to_anchor=(1.1, 1.0375), ncol=2,\n",
    "    columnspacing=0.5, title='\\\\hphantom{\\\\text{.}} \\\\hspace{0.2cm} '\n",
    "    '\\\\textbf{CMS} \\\\hspace{0.8cm} \\\\textbf{Non-Private}')\n",
    "\n",
    "fig.tight_layout()\n",
    "AUC_DB.to_pickle(f'imgs/{setting}.pkl')\n",
    "fig.savefig(f'imgs/{setting}_prec_mr.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf score\n",
    "setting = 'news'\n",
    "\n",
    "fig, axs = init_figure(1, 2, 'ieee')\n",
    "plot_conf(f'{setting}_uniform_prior', axs[0])\n",
    "axs[0].set_title('$\\\\text{Adv}_\\\\textit{weak}$')\n",
    "\n",
    "plot_conf(f'{setting}_estimated_prior', axs[1])\n",
    "axs[1].set_title('$\\\\text{Adv}_\\\\textit{strong}$')\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "# legend\n",
    "axs[-1].legend(bbox_to_anchor=(1.1, 1.0375))\n",
    "\n",
    "fig.savefig(f'imgs/{setting}_conf.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour (uniform)\n",
    "setting = 'news'\n",
    "prior_type = 'uniform'\n",
    "exp_name = f'{setting}_{prior_type}_prior'\n",
    "n_pools = 5\n",
    "\n",
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "plot_gammadelta(exp_name, axs, n_pools)\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig(f'imgs/{exp_name}_cont.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour (estimated)\n",
    "setting = 'news'\n",
    "prior_type = 'estimated'\n",
    "exp_name = f'{setting}_{prior_type}_prior'\n",
    "n_pools = 5\n",
    "\n",
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "plot_gammadelta(exp_name, axs, n_pools)\n",
    "\n",
    "# remove unnecessary labels and ticks\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.savefig(f'imgs/{exp_name}_cont.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All confidence score plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "ax_id = 0\n",
    "for setting in ['emojis', 'news']:\n",
    "    for prior_type, prior_name in zip(['uniform', 'estimated'],\n",
    "                                      ['$\\\\text{Adv}_\\\\textit{weak}$', '$\\\\text{Adv}_\\\\textit{strong}$']):\n",
    "        ax = axs[ax_id]\n",
    "        plot_conf(f'{setting}_{prior_type}_prior', ax=ax)\n",
    "        ax_id += 1\n",
    "        \n",
    "        if ax_id != 1:\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_yticklabels([])\n",
    "        \n",
    "        setting_str = 'Emojis' if setting == 'emojis' else 'Web domains'\n",
    "        ax.set_title(f'{setting_str}, {prior_name}')\n",
    "axs[-1].legend(bbox_to_anchor=(1.1, 1.0375))\n",
    "fig.tight_layout()\n",
    "fig.savefig('imgs/all_conf.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack on Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter data parameters\n",
    "setting = 'twitter'\n",
    "U, m, k, eps = 3239, 1024, 65536, 4\n",
    "pool_sizes = [273, 222, 263, 267, 184, 395]\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "# place pre-processed attack dataset and external dataset into this location\n",
    "users_file = f'pickles/{setting}_att.json'\n",
    "ref_file = f'pickles/{setting}_ext.pickle'\n",
    "\n",
    "if not os.path.isfile(users_file):\n",
    "    raise Exception(f'Dataset not found at {users_file}')\n",
    "if not os.path.isfile(ref_file):\n",
    "    raise Excepion(f'Auxiliary dataset not found at {ref_file}')\n",
    "\n",
    "# load user ids\n",
    "with open(users_file, 'r') as f:\n",
    "    users_data = json.load(f)\n",
    "user_ids = users_data.keys()\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=len(user_ids))\n",
    "\n",
    "logging.info(f'{setting} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{setting} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    # generate/load prior\n",
    "    ref_emojis = np.array(pickle.load(open(ref_file, 'rb')))\n",
    "    load_prior(U, m, k, eps, pool_sizes, prior_filename=prior, objects=ref_emojis)\n",
    "    logging.info(f'{setting} => loaded prior')\n",
    "    logging.info(f'{setting} => finished setting up')\n",
    "\n",
    "    # only run experiment on estimated prior\n",
    "    prior_type = 'estimated'\n",
    "    curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "    # initialize DB to write result to\n",
    "    sub_folder = f'{setting}_{prior_type}_prior'\n",
    "    exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "    os.makedirs(f'{exps_folder}/{sub_folder}/exp_pickles', exist_ok=True)\n",
    "    EXP_DB = pd.DataFrame(columns=['unique_id', 'n', 'k', 'acc'])\n",
    "\n",
    "    logging.info(f'{setting} => starting')\n",
    "\n",
    "    for n in ns:\n",
    "        unique_id = uuid.uuid4().hex[:5]\n",
    "        logging.info(f'{setting}, {n} => starting')\n",
    "        pbar = tqdm(total=len(user_ids), desc=f'n = {n}: ')\n",
    "        acc, results = attack_real_users(n, user_ids, users_file,\n",
    "            user_seeds, shared_cms, pool_sizes, prior, pbar=pbar)\n",
    "        logging.info(f'{setting}, {n} => finished')\n",
    "\n",
    "        EXP_DB = EXP_DB.append({'unique_id': unique_id, 'n': n, 'k': k, 'acc': acc}, ignore_index=True)\n",
    "        pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "        pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "\n",
    "    logging.info(f'{setting} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "## run non private\n",
    "np_cms = (U, U, math.inf, 0, None, None)\n",
    "sub_folder = f'{setting}_non_private'\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "os.makedirs(f'{exps_folder}/{sub_folder}/exp_pickles', exist_ok=True)\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'n', 'k', 'acc'])\n",
    "for n in ns:\n",
    "    unique_id = uuid.uuid4().hex[:5]\n",
    "    logging.info(f'{setting}, non-private, {n} => starting')\n",
    "    pbar = tqdm(total=len(user_ids), desc=f'n = {n}: ')\n",
    "    acc, results = attack_real_users(n, user_ids, users_file,\n",
    "        user_seeds, np_cms, pool_sizes, prior, pbar=pbar)\n",
    "    logging.info(f'{setting}, non-private, {n} => finished')\n",
    "\n",
    "    EXP_DB = EXP_DB.append({'unique_id': unique_id, 'n': n, 'k': 0, 'acc': acc}, ignore_index=True)\n",
    "    pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "    pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "logging.info(f'{setting} => finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot prec-nr and conf score on same plot\n",
    "fig, axs = init_figure(1, 2, 'ieee_double')\n",
    "ns = [7, 30, 90, 180]\n",
    "n_pools = 6\n",
    "setting = 'twitter'\n",
    "\n",
    "## prec-nr\n",
    "ax = axs[0]\n",
    "# plot estimated prior\n",
    "AUC_DB = plot_prec_nr(f'{setting}_estimated_prior', ax, n_pools=n_pools)\n",
    "# plot non-private\n",
    "AUC_DB = plot_prec_nr(f'{setting}_non_private', ax, n_pools=n_pools,\n",
    "    AUC_DB=AUC_DB, nonprivate=True)\n",
    "AUC_DB.to_pickle(f'imgs/{setting}.pkl')\n",
    "\n",
    "# custom legend\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "handles = h[1:5] + [h[0]] + h[5:]\n",
    "labels = l[1:5] + [l[0]] + l[5:]\n",
    "ax.legend(handles, labels, bbox_to_anchor=(1, 1.0375), ncol=2, columnspacing=0.5,\n",
    "          title='\\\\hphantom{\\\\text{.}} \\\\hspace{0.2cm} \\\\textbf{Private} \\\\hspace{0.8cm} \\\\textbf{Non-Private}')\n",
    "\n",
    "# conf score\n",
    "ax = axs[1]\n",
    "ns = [7, 30, 90, 180]\n",
    "EXP_DB = pickle.load(open(f'{exps_folder}/{setting}_estimated_prior/EXP_DB.pickle', 'rb'))\n",
    "EXP_DB = EXP_DB[EXP_DB['k'] != 0]\n",
    "for (i, n) in enumerate(ns):\n",
    "    unique_id = EXP_DB[EXP_DB['n'] == n]['unique_id'].iloc[0]\n",
    "    plot_spl_conf(f'{exps_folder}/{setting}_estimated_prior/exp_pickles/{unique_id}.pickle',\n",
    "                  ax, colors_to_use[len(ns)][i], label=f'$n = {n}$')\n",
    "ax.legend(bbox_to_anchor=(1, 1.025))\n",
    "ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=1.8)\n",
    "fig.savefig(f'imgs/{setting}_prec_nr_conf.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap of precision\n",
    "setting = 'twitter'\n",
    "prior_type = 'estimated'\n",
    "\n",
    "fig, axs = init_figure(1, 4, 'ieee_quadruple')\n",
    "folder = f'{exps_folder}/{setting}_{prior_type}_prior'\n",
    "ns = [7, 30, 90, 180]\n",
    "EXP_DB = pickle.load(open(f'{folder}/EXP_DB.pickle', 'rb'))\n",
    "EXP_DB = EXP_DB[EXP_DB['k'] != 0]\n",
    "for (i, n) in enumerate(ns):\n",
    "    unique_id = EXP_DB[EXP_DB['n'] == n]['unique_id'].iloc[0]\n",
    "    plot_gammadelta_heatmap(f'{folder}/exp_pickles/{unique_id}.pickle', axs[i])\n",
    "    axs[i].set_title(f'$n = {n}$')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.label_outer()\n",
    "fig.tight_layout(w_pad=3)\n",
    "fig.savefig(f'imgs/{setting}_{prior_type}_prior_cont.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap of distribution\n",
    "setting = 'twitter'\n",
    "prior_type = 'estimated'\n",
    "\n",
    "fig, ax = init_figure(1, 1, 'ieee')\n",
    "folder = f'{exps_folder}/{setting}_{prior_type}_prior/'\n",
    "n = 30\n",
    "EXP_DB = pickle.load(open(f'{folder}/EXP_DB.pickle', 'rb'))\n",
    "EXP_DB = EXP_DB[EXP_DB['k'] != 0]\n",
    "unique_id = EXP_DB[EXP_DB['n'] == n]['unique_id'].iloc[0]\n",
    "plot_gammadelta_heatmap(f'{folder}/exp_pickles/{unique_id}.pickle', ax, plot='dist')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'imgs/{setting}_{prior_type}_prior_dist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis parameters\n",
    "setting = 'emojis'\n",
    "U, m, k, eps = 2600, 1024, 65536, 4\n",
    "n = 180\n",
    "Ps = [10, 50, 200, 400]\n",
    "kappas = [0, 0.5, 1, 2, 4]\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'P', 's', 'entropy', 'auc'])\n",
    "sub_folder = f'{setting}_entropy'\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "num_users = 5000\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{sub_folder} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{sub_folder} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    for P in Ps:\n",
    "        logging.info(f'{sub_folder}, {P} => starting')\n",
    "        for kappa in kappas:\n",
    "            unique_id = uuid.uuid4().hex[:5]\n",
    "            pool_sizes = [P for _ in range(6)]\n",
    "            p_omega = f'{p_omegas_folder}/{setting}_p_omega_{P}_{kappa}.pickle'\n",
    "\n",
    "            # generate/load zipf p_\\Omega\n",
    "            if not os.path.isfile(p_omega):\n",
    "                universe = np.arange(U)\n",
    "                p_omega_f = np.concatenate([zip_pdf(kappa, p) for p in pool_sizes] +\n",
    "                                           [zip_pdf(kappa, U - sum(pool_sizes))])\n",
    "                p_omega_f /= p_omega_f.sum()\n",
    "                pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "            logging.info(f'{sub_folder}, {P}, {kappa} => loaded p_omega')\n",
    "\n",
    "            # prior is same as p_\\Omega in this setting\n",
    "            prior = p_omega\n",
    "            logging.info(f'{sub_folder}, {P}, {kappa} => finished setting up')\n",
    "\n",
    "            # only run experiment with estimated prior\n",
    "            prior_type = 'estimated'\n",
    "            curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "            # pack experiment parameters into object\n",
    "            exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "                exp_db_filename=exp_db_filename, reps=num_users,\n",
    "                p_omega=p_omega, prior=curr_prior, n=n, EXP_DB=EXP_DB)\n",
    "\n",
    "            logging.info(f'{sub_folder}, {P}, {kappa} => starting')\n",
    "\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'P = {P}, kappa = {kappa}: ')\n",
    "            acc, results = attack(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{sub_folder}, {prior_type}, {n} => finished')\n",
    "            \n",
    "            # get auc\n",
    "            _, _, curr_auc = parse_pickle_prec_nr(results=results)\n",
    "            # calculate entropy\n",
    "            pool_probs = zip_pdf(kappa, P)\n",
    "            curr_entropy = -np.sum(pool_probs * np.log(pool_probs))\n",
    "            EXP_DB = EXP_DB.append({\n",
    "                'unique_id': unique_id, 'P': P, 's': kappa, 'entropy': curr_entropy, 'auc': curr_auc\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "            pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "            logging.info(f'{sub_folder}, {P}, {kappa} => finished')\n",
    "        logging.info(f'{sub_folder}, {P} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "# write a copy of result database to images folder to commit it to git\n",
    "pickle.dump(EXP_DB, open(f'imgs/{sub_folder}.pkl', 'wb'))\n",
    "logging.info(f'{sub_folder} => finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-processing before attack\n",
    "# emojis parameters\n",
    "setting = 'emojis'\n",
    "U, m, k, eps = 2600, 1024, 65536, 4\n",
    "pool_sizes = [228, 228, 228, 228, 228, 228]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "sigmas = [0, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "sigma_strs = ['0', '1e-5', '1e-4', '1e-3', '1e-2']\n",
    "\n",
    "# load p_\\Omega\n",
    "p_omega_f = pickle.load(open(p_omega, 'rb'))\n",
    "\n",
    "# calculate average JSD for each sigma\n",
    "def kld(p, q):\n",
    "    res = 0\n",
    "    for (p_x, q_x) in zip(p, q):\n",
    "        if p_x != 0:\n",
    "            res += p_x * np.log2(p_x / q_x)\n",
    "    return res\n",
    "\n",
    "def jsd(p, q):\n",
    "    m = (p + q) / 2\n",
    "    return (kld(p, m) + kld(q, m)) / 2\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "reps = 5000\n",
    "\n",
    "# generate/load prior\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "load_prior(U, m, k, eps, pool_sizes, p_omega, prior)\n",
    "prior_f = pickle.load(open(prior, 'rb'))\n",
    "\n",
    "sigma_jsd = dict()\n",
    "for (sigma, sigma_str) in tqdm(zip(sigmas, sigma_strs)):\n",
    "    avg_jsd = 0\n",
    "    jsds = np.zeros(reps)\n",
    "    for rep in range(reps):\n",
    "        # generate a valid p_usr\n",
    "        p_usr = p_omega_f + np.random.normal(scale=sigma, size=p_omega_f.shape)\n",
    "        p_usr += np.abs(p_usr.min())\n",
    "        p_usr /= p_usr.sum()\n",
    "\n",
    "        jsds[rep] = jsd(prior_f, p_usr)\n",
    "    sigma_jsd[sigma] = jsds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actual attack\n",
    "# emojis parameters\n",
    "setting = 'emojis'\n",
    "U, m, k, eps = 2600, 1024, 65536, 4\n",
    "pool_sizes = [228, 228, 228, 228, 228, 228]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "sigmas = [0, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "sigma_strs = ['0', '1e-5', '1e-4', '1e-3', '1e-2']\n",
    "\n",
    "sub_folder = f'{setting}_robustness'\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'sigma', 'n', 'avgD', 'auc'])\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "num_users = 5000\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{sub_folder} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{sub_folder} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    # generate/load zipf p_\\Omega\n",
    "    if not os.path.isfile(p_omega):\n",
    "        universe = np.arange(U)\n",
    "        p_omega_f = np.concatenate([zip_pdf(kappa, p) for p in pool_sizes] +\n",
    "                                   [zip_pdf(kappa, U - sum(pool_sizes))])\n",
    "        p_omega_f /= p_omega_f.sum()\n",
    "        pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "\n",
    "    # generate/load prior\n",
    "    load_prior(U, m, k, eps, pool_sizes, p_omega, prior)\n",
    "    logging.info(f'{sub_folder} => loaded prior')\n",
    "    logging.info(f'{sub_folder} => finished setting up')\n",
    "\n",
    "    for (sigma, sigma_str) in zip(sigmas, sigma_strs):\n",
    "        logging.info(f'{sub_folder}, {sigma_str} => starting')\n",
    "        \n",
    "        # only run experiment with estimated prior\n",
    "        prior_type = 'estimated'\n",
    "        curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "        # pack experiment parameters into object\n",
    "        exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "            exp_db_filename=exp_db_filename, reps=num_users,\n",
    "            p_omega=p_omega, prior=curr_prior, sigma=sigma, EXP_DB=EXP_DB)\n",
    "\n",
    "        for n in ns:\n",
    "            unique_id = uuid.uuid4().hex[:5]\n",
    "            exp_params.n = n\n",
    "            logging.info(f'{sub_folder}, {sigma_str}, {n} => starting')\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'sigma = {sigma_str}, n = {n}: ')\n",
    "            acc, results = attack(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{sub_folder}, {sigma_str}, {n} => finished')\n",
    "            \n",
    "            # get auc\n",
    "            _, _, curr_auc = parse_pickle_prec_nr(results=results)\n",
    "            # get avgD\n",
    "            curr_avgD = sigma_jsd[sigma]\n",
    "            EXP_DB = EXP_DB.append({\n",
    "                'unique_id': unique_id, 'sigma': sigma, 'n': n, 'avgD': curr_avgD, 'auc': curr_auc\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "            pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "\n",
    "            logging.info(f'{sub_folder}, {sigma_str}, {n} => finished')\n",
    "        logging.info(f'{sub_folder}, {sigma_str} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "# write a copy of result database to images folder to commit it to git\n",
    "pickle.dump(EXP_DB, open(f'imgs/{sub_folder}.pkl', 'wb'))\n",
    "logging.info(f'{sub_folder} => finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of the universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web domains parameters\n",
    "setting = 'news'\n",
    "m, k, eps = 1024, 65536, 8\n",
    "ns = [7, 30, 90, 180]\n",
    "Us = [1000, 10000, 100000, 250000]\n",
    "pool_sizes = [14, 13, 13, 10, 10]\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'U', 'n', 'auc'])\n",
    "sub_folder = f'{setting}_size_of_universe'\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "num_users = 5000\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{sub_folder} => starting')\n",
    "\n",
    "for U in Us:\n",
    "    try:\n",
    "        logging.info(f'{sub_folder}, {U} => starting')\n",
    "        # load cms into shared memory (don't save to file)\n",
    "        shared_cms = load_cms(U, m, k, eps=eps, shared=True, save_to_file=False)\n",
    "        logging.info(f'{sub_folder}, {U} => loaded shared cms')\n",
    "        \n",
    "        for n in ns:\n",
    "            unique_id = uuid.uuid4().hex[:5]\n",
    "            p_omega = f'{p_omegas_folder}/{setting}_p_omega_{U}.pickle'\n",
    "\n",
    "            # generate/load random p_\\Omega\n",
    "            if not os.path.isfile(p_omega):\n",
    "                universe = np.arange(U)\n",
    "                p_omega_f = np.concatenate([random_pdf(p) for p in pool_sizes] +\n",
    "                                           [random_pdf(U - sum(pool_sizes))])\n",
    "                p_omega_f /= p_omega_f.sum()\n",
    "\n",
    "                pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "            logging.info(f'{sub_folder}, {U}, {n} => loaded p_omega')\n",
    "            logging.info(f'{sub_folder}, {U}, {n} => finished setting up')\n",
    "\n",
    "            # only run experiment with uniform prior\n",
    "            prior_type = 'uniform'\n",
    "            curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "            # pack experiment parameters into object\n",
    "            exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "                exp_db_filename=exp_db_filename, reps=num_users,\n",
    "                p_omega=p_omega, prior=curr_prior, n=n, EXP_DB=EXP_DB)\n",
    "\n",
    "            logging.info(f'{sub_folder}, {U}, {n} => starting')\n",
    "\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'U = {U}, n = {n}: ')\n",
    "            acc, results = attack(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{sub_folder}, {U}, {n} => finished')\n",
    "            \n",
    "            # get auc\n",
    "            _, _, curr_auc = parse_pickle_prec_nr(results=results)\n",
    "            EXP_DB = EXP_DB.append({\n",
    "                'unique_id': unique_id, 'U': U, 'n': n, 'auc': curr_auc\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "            pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "            logging.info(f'{sub_folder}, {U}, {n} => finished')\n",
    "        logging.info(f'{sub_folder}, {U} => finished')\n",
    "    finally:\n",
    "        unload_cms(shared_cms)\n",
    "\n",
    "# write a copy of result database to images folder to commit it to git\n",
    "pickle.dump(EXP_DB, open(f'imgs/{sub_folder}.pkl', 'wb'))\n",
    "logging.info(f'{sub_folder} => finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of $\\varepsilon$ on AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news parameters\n",
    "setting = 'news'\n",
    "U, m, k = 2000, 1024, 65536\n",
    "pool_sizes = [14, 13, 13, 10, 10]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "prior = f'{priors_folder}/{setting}_prior.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "epses = [0.01, 0.1, 1, 4, 8]\n",
    "\n",
    "sub_folder = f'{setting}_eps'\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'eps', 'n', 'auc'])\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "num_users = 5000\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{sub_folder} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{sub_folder} => loaded shared cms')\n",
    "\n",
    "try:\n",
    "    # generate/load random p_\\Omega\n",
    "    if not os.path.isfile(p_omega):\n",
    "        universe = np.arange(U)\n",
    "        p_omega_f = np.concatenate([random_pdf(p) for p in pool_sizes] +\n",
    "                                   [random_pdf(U - sum(pool_sizes))])\n",
    "        p_omega_f /= p_omega_f.sum()\n",
    "\n",
    "    logging.info(f'{sub_folder} => finished setting up')\n",
    "\n",
    "    for eps in epses:\n",
    "        logging.info(f'{sub_folder}, {sigma_str} => starting')\n",
    "        \n",
    "        # only run experiment with uniform prior\n",
    "        prior_type = 'uniform'\n",
    "        curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "        # pack experiment parameters into object\n",
    "        shared_cms = set_cms_eps(shared_cms, eps)\n",
    "        exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "            exp_db_filename=exp_db_filename, reps=num_users,\n",
    "            p_omega=p_omega, prior=curr_prior, sigma=sigma, EXP_DB=EXP_DB)\n",
    "\n",
    "        for n in ns:\n",
    "            unique_id = uuid.uuid4().hex[:5]\n",
    "            exp_params.n = n\n",
    "            logging.info(f'{sub_folder}, {eps}, {n} => starting')\n",
    "            pbar = tqdm(total=exp_params.reps, desc=f'eps = {eps}, n = {n}: ')\n",
    "            acc, results = attack(exp_params, user_seeds=user_seeds, pbar=pbar)\n",
    "            logging.info(f'{sub_folder}, {eps}, {n} => finished')\n",
    "            \n",
    "            # get auc\n",
    "            _, _, curr_auc = parse_pickle_prec_nr(results=results)\n",
    "            EXP_DB = EXP_DB.append({\n",
    "                'unique_id': unique_id, 'eps': eps, 'n': n, 'auc': curr_auc\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "            pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "\n",
    "            logging.info(f'{sub_folder}, {eps}, {n} => finished')\n",
    "        logging.info(f'{sub_folder}, {eps} => finished')\n",
    "finally:\n",
    "    unload_cms(shared_cms)\n",
    "\n",
    "# write a copy of result database to images folder to commit it to git\n",
    "pickle.dump(EXP_DB, open(f'imgs/{sub_folder}.pkl', 'wb'))\n",
    "logging.info(f'{sub_folder} => finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of $\\varepsilon$ on Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'news'\n",
    "U, m, k = 2000, 1024, 65536\n",
    "epses = [0.01, 0.1, 1, 4, 8]\n",
    "ns = [10**6, 10**7, 10**8, 10**9]\n",
    "max_workers = 38\n",
    "\n",
    "sub_folder = f'{setting}_utility_vs_eps'\n",
    "EXP_DB = pd.DataFrame(columns=['eps', 'n', 'mae', 'mape_80'])\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "os.makedirs(f'{exps_folder}/{sub_folder}/exp_pickles/', exist_ok=True)\n",
    "\n",
    "logging.info(f'{sub_folder} => starting')\n",
    "\n",
    "# Share sketch matrix on shared_memory to conserve space\n",
    "M = np.zeros((k, m))\n",
    "shm_Ms, shared_Ms = [], []\n",
    "for _ in tqdm(range(max_workers)):\n",
    "    shm_M = SharedMemory(create = True, size = M.nbytes)\n",
    "    shared_M = np.ndarray(shape=M.shape, dtype=M.dtype, buffer=shm_M.buf)\n",
    "    shared_M[:] = M[:]\n",
    "\n",
    "    shm_Ms.append(shm_M)\n",
    "    shared_Ms.append(shared_M)\n",
    "logging.info(f'{sub_folder} => allocated memory for sketch matrices in shared memory')\n",
    "logging.info(f'{sub_folder} => finished setting up')\n",
    "\n",
    "# load p_\\Omega\n",
    "p_omega_f = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "p_omega = pickle.load(open(p_omega_f, 'rb'))\n",
    "\n",
    "# choose top X% or i objects\n",
    "sort_inds = np.flip(np.argsort(p_omega))\n",
    "X = 0.8\n",
    "x = int(X * len(p_omega))\n",
    "top_x_p_omega = p_omega[sort_inds[:x]]\n",
    "\n",
    "try:\n",
    "    for n in ns:\n",
    "        logging.info(f'{sub_folder}, {n} => starting')\n",
    "        for (i, eps) in enumerate(epses):\n",
    "            logging.info(f'{sub_folder}, {n}, {eps} => starting')\n",
    "            freqs = run_utility_vs_eps(n, U, m, k, eps, p_omega_f, shm_Ms, shared_Ms, max_workers)\n",
    "            freqs = np.array(freqs) / n\n",
    "            \n",
    "            curr_mae = np.mean(np.abs(freqs - p_omega))\n",
    "            top_x_freqs = freqs[sort_inds[:x]]\n",
    "            curr_mape_80 = np.mean(np.abs(top_x_freqs - top_x_p_omega) / top_x_p_omega) * 100\n",
    "            \n",
    "            EXP_DB = EXP_DB.append({\n",
    "                'eps': eps, 'n': n, 'mae': curr_mae, 'mape_80': curr_mape_80\n",
    "            }, ignore_index=True)\n",
    "            pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "            with open(f'{exps_folder}/{sub_folder}/exp_pickles/{n}_{eps}.npy', 'wb') as result_f:\n",
    "                np.save(result_f, freqs)\n",
    "\n",
    "            logging.info(f'{sub_folder}, {n}, {eps} => finished')\n",
    "        logging.info(f'{sub_folder}, {n} => finished')\n",
    "finally:\n",
    "    # clear shared memory\n",
    "    for shm_M in shm_Ms:\n",
    "        shm_M.close()\n",
    "        shm_M.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web domains parameters\n",
    "setting = 'news'\n",
    "U, m, k, eps = 2000, 2000, 65536, 8\n",
    "pool_sizes = [14, 13, 13, 10, 10]\n",
    "p_omega = f'{p_omegas_folder}/{setting}_p_omega.pickle'\n",
    "prior = f'{priors_folder}/{setting}_prior_{m}.pickle'\n",
    "ns = [7, 30, 90, 180]\n",
    "\n",
    "sub_folder = f'{setting}_hashing'\n",
    "EXP_DB = pd.DataFrame(columns=['unique_id', 'prior_type', 'n', 'auc'])\n",
    "exp_db_filename = f'{exps_folder}/{sub_folder}/EXP_DB.pickle'\n",
    "\n",
    "# number of users can be smaller because we don't plot gamma, delta\n",
    "num_users = 5000\n",
    "\n",
    "# user metadata\n",
    "user_seeds = np.random.randint(0, 2147483647, size=num_users)\n",
    "\n",
    "logging.info(f'{setting} => starting')\n",
    "\n",
    "# load cms into shared memory\n",
    "shared_cms = load_cms(U, m, k, eps=eps, shared=True)\n",
    "logging.info(f'{setting} => loaded shared cms')\n",
    "\n",
    "# generate/load random p_\\Omega\n",
    "if not os.path.isfile(p_omega):\n",
    "    universe = np.arange(U)\n",
    "    p_omega_f = np.concatenate([random_pdf(p) for p in pool_sizes] +\n",
    "                               [random_pdf(U - sum(pool_sizes))])\n",
    "    p_omega_f /= p_omega_f.sum()\n",
    "\n",
    "    pickle.dump(p_omega_f, open(p_omega, 'wb'))\n",
    "logging.info(f'{setting} => loaded p_omega')\n",
    "\n",
    "# generate/load prior\n",
    "load_prior(U, m, k, eps, pool_sizes, p_omega, prior)\n",
    "logging.info(f'{setting} => loaded prior')\n",
    "logging.info(f'{setting} => finished setting up')\n",
    "\n",
    "for prior_type in ['estimated', 'uniform']:\n",
    "    curr_prior = None if prior_type == 'uniform' else prior\n",
    "\n",
    "    # pack experiment parameters into object\n",
    "    exp_params = ExpParams(shared_cms, pool_sizes,\n",
    "        exp_db_filename=exp_db_filename, reps=num_users,\n",
    "        p_omega=p_omega, prior=curr_prior, EXP_DB=EXP_DB)\n",
    "\n",
    "    logging.info(f'{setting}, {prior_type} => starting')\n",
    "\n",
    "    for n in ns:\n",
    "        unique_id = uuid.uuid4().hex[:5]\n",
    "        exp_params.n = n\n",
    "        logging.info(f'{setting}, {prior_type}, {n} => starting')\n",
    "        pbar = tqdm(total=num_users, desc=f'n = {n}: ')\n",
    "        acc, results = attack(exp_params, pbar=pbar)\n",
    "        logging.info(f'{setting}, {prior_type}, {n} => finished')\n",
    "\n",
    "        # get auc\n",
    "        _, _, curr_auc = parse_pickle_prec_nr(results=results)\n",
    "        EXP_DB = EXP_DB.append({'unique_id': unique_id, 'prior_type': prior_type, 'n': n, 'auc': curr_auc},\n",
    "                               ignore_index=True)\n",
    "        pickle.dump(EXP_DB, open(exp_db_filename, 'wb'))\n",
    "        pickle.dump(results, open(f'{exps_folder}/{sub_folder}/exp_pickles/{unique_id}.pickle', 'wb'))\n",
    "\n",
    "    logging.info(f'{setting}, {prior_type} => finished')\n",
    "\n",
    "logging.info(f'{setting} => finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = init_figure(1, 1, 'ieee_triple')\n",
    "p_omega = f'{p_omegas_folder}/emojis_p_omega.pickle'\n",
    "p_omega = pickle.load(open(p_omega, 'rb'))\n",
    "\n",
    "xs = np.arange(len(p_omega))\n",
    "ax.plot(xs, p_omega, color=colors_to_use[1][0], linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Object')\n",
    "ax.set_ylabel('Probability mass')\n",
    "ax.set_xlim(0, 2599)\n",
    "ax.set_xticks([0, 500, 1000, 1500, 2000, 2500, 2599])\n",
    "fig.savefig('imgs/zipf_mixture.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
